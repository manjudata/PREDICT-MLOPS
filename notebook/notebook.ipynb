{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a97ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../artifacts/raw/vehicledata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbc4aa",
   "metadata": {},
   "source": [
    "Beginning with RandomForest model, since it is good for large dataset with multiple features. Also there is no need for any data imputation since no missing value is there.\n",
    "\n",
    "The target here is Maintenance Required or not.\n",
    "\n",
    "Features like Vehicle ID, Make and model, Vehicle type and Route Info can be easily dropped.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf691d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ffb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be97659",
   "metadata": {},
   "source": [
    "We need to now convert the object types into numeric data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d857c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1305be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b332ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d217e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    if col in df.columns:  # Only process existing columns\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec63e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1bd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    if col in df.columns:  # Only process existing columns\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "        print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef31773",
   "metadata": {},
   "source": [
    "Now i need to convert the categorical values into numerical values, and for which i would use different types of encodings. Depending upon the type of data is present in each categorical columns, which we already saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32069549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Last_Maintenance_Date'] = pd.to_datetime(df['Last_Maintenance_Date'])\n",
    "\n",
    "df['Maintenance_Year'] = df['Last_Maintenance_Date'].dt.year\n",
    "df['Maintenance_Month'] = df['Last_Maintenance_Date'].dt.month\n",
    "df['Maintenance_Day'] = df['Last_Maintenance_Date'].dt.day\n",
    "df['Maintenance_Weekday'] = df['Last_Maintenance_Date'].dt.weekday\n",
    "\n",
    "df.drop('Last_Maintenance_Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7311ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "         print(f\"\\nColumn: {col}\")\n",
    "         print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d8d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Vehicle_ID','Make_and_Model','Route_Info'], axis = 1)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36149fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['Maintenance_Type', 'Weather_Conditions', 'Road_Conditions']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 1. Encode binary column: Vehicle_Type\n",
    "le = LabelEncoder()\n",
    "df['Vehicle_Type'] = le.fit_transform(df['Vehicle_Type'])\n",
    "\n",
    "brake_map = {'Good': 2, 'Fair': 1, 'Poor': 0}\n",
    "df['Brake_Condition'] = df['Brake_Condition'].map(brake_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24853100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "print(df.columns.tolist())\n",
    "\n",
    "df = pd.get_dummies(df, columns = ['Maintenance_Type', 'Weather_Conditions', 'Road_Conditions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f967f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_cols.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce03d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['Maintenance_Type_Engine Overhaul', 'Maintenance_Type_Oil Change', 'Maintenance_Type_Tire Rotation', 'Weather_Conditions_Clear', 'Weather_Conditions_Rainy', 'Weather_Conditions_Snowy', 'Weather_Conditions_Windy', 'Road_Conditions_Highway', 'Road_Conditions_Rural', 'Road_Conditions_Urban']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all bool columns to int (optional, safe)\n",
    "df = df.astype({col: 'int' for col in df.select_dtypes(include='bool').columns})\n",
    "print(df[['Maintenance_Type_Engine Overhaul', 'Maintenance_Type_Oil Change', 'Maintenance_Type_Tire Rotation', 'Weather_Conditions_Clear', 'Weather_Conditions_Rainy', 'Weather_Conditions_Snowy', 'Weather_Conditions_Windy', 'Road_Conditions_Highway', 'Road_Conditions_Rural', 'Road_Conditions_Urban']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1181c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ada90",
   "metadata": {},
   "source": [
    "## Let's build the model: RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e221c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9420bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Maintenance_Required', axis=1)\n",
    "y = df['Maintenance_Required']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db71189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b56283",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07985aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.select_dtypes(include=['object', 'string', 'category']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087459ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde88cfa",
   "metadata": {},
   "source": [
    "The accuracy we recieved is too good to be true, there has been some leakage, and we check i# t by seeing the correlation.# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['Maintenance_Required'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3693be4",
   "metadata": {},
   "source": [
    "Here we see that, some columns have had some high correlation, like\n",
    "\n",
    "Anomalies_Detected 0.499375\n",
    "Failure_History 0.448371\n",
    "Downtime_Maintenance 0.274428\n",
    "keyboard_arrow_down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e70e6",
   "metadata": {},
   "source": [
    "What we found\n",
    "Here, we can see taht some columns have high correlation and we need to fix that, for that we would drop columns like engine temperature as it only has one value, and doesn't really add anything in the model for us. Next up we have leakage features, which the model shouldn't see first hand because that is cheating my friend. It's like you giving an exam and get to see the question paper beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Engine_Temperature'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f35fc69",
   "metadata": {},
   "source": [
    "So here we drop these features that the model shouldn't see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "leakage_features = [\n",
    "    'Anomalies_Detected',\n",
    "    'Failure_History',\n",
    "    'Downtime_Maintenance',\n",
    "    'Predictive_Score'  # also suspiciously correlated\n",
    "]\n",
    "X = df.drop(['Maintenance_Required'] + leakage_features, axis=1)\n",
    "y = df['Maintenance_Required']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bd24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89f90b",
   "metadata": {},
   "source": [
    "Now, an accuracy of 77 percent, atleast feels real, but here we need to see if our dataset is balanced, that is, is there enough data for both \"maintenance required\" and \"maintenance not required\", or is the data manipulated already to give us a biased result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb35ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2970d308",
   "metadata": {},
   "source": [
    "Clearly, the model is baised to give us result in the favor of \"maintenance required\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7995ec",
   "metadata": {},
   "source": [
    "To balance things out\n",
    "we do some balancing of our data and for that we use the class weight balanced. And re-evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e83ab2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Balanced class weights\n",
    "rf_balanced = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "rf_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_balanced = rf_balanced.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_balanced))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_balanced))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9193e",
   "metadata": {},
   "source": [
    "So, no such great changes have been achieved, that means our dataset is unbalanced to such extent that only adding some weight won't suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4f212",
   "metadata": {},
   "source": [
    "Let's use SMOTE (Synthetic Minority Over-Sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d48b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 2: Split the new balanced dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Step 3: Train the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c435e3",
   "metadata": {},
   "source": [
    "What does SMOTE do? It generates synthetic data that would cover up for the unbalanced number of data for a particular outcome. Here, the dataset was unbalanced in the favour of giving results for \"maintenance required\". So SMOTE made additions of some synthetic/fake dataset that would balance things out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')\n",
    "plt.title(\"Top 15 Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X_resampled, y_resampled, cv=5)\n",
    "print(\"CV Accuracy scores:\", scores)\n",
    "print(\"Mean CV Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075e693",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07e49625",
   "metadata": {},
   "source": [
    "Cross-validation is a technique to:\n",
    "\n",
    "Test how well your model generalizes to unseen data\n",
    "Reduce the risk of overfitting or underfitting\n",
    "Provide a more robust estimate of model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
